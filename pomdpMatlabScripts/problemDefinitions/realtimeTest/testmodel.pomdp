discount: 0.9
values: reward
states: s1 s2
actions: a1 a2  
observations: o1 o2

start: 0.1 0.9

# T: <action> : <start-state> : <end-state> %f
T: a1 : s1 : s1 0.3
T: a1 : s1 : s2 0.7
T: a1 : s2 : s1 0.6
T: a1 : s2 : s2 0.4
T: a2 : s1 : s1 0.1
T: a2 : s1 : s2 0.9
T: a2 : s2 : s1 0.8
T: a2 : s2 : s2 0.2

#O : <action> : <end-state> : <observation> %f
O: a1 : s1 : o1 0.9 
O: a1 : s1 : o2 0.1 
O: a1 : s2 : o1 0.5 
O: a1 : s2 : o2 0.5 
O: a2 : s1 : o1 0.9 
O: a2 : s1 : o2 0.1 
O: a2 : s2 : o1 0.5 
O: a2 : s2 : o2 0.5

#R: <action> : <start-state> : <end-state> : <observation> %f

R: a1 : s1 : * : * 2
R: a2 : s1 : * : * 1
R: a1 : s2 : * : * 1
R: a2 : s2 : * : * 3
